"""
Verify Manual Documents Import

Script ki·ªÉm tra k·∫øt qu·∫£ import v√† t·∫°o b√°o c√°o th·ªëng k√™
"""

import os
from supabase import create_client, Client
from dotenv import load_dotenv
import sys
from collections import Counter

# Load environment variables
load_dotenv()

SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_SERVICE_KEY = os.getenv("SUPABASE_SERVICE_KEY")

if not SUPABASE_URL or not SUPABASE_SERVICE_KEY:
    print("‚ùå Error: SUPABASE_URL and SUPABASE_SERVICE_KEY must be set in .env")
    sys.exit(1)

# Initialize Supabase client
supabase: Client = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)


def verify_import():
    """Verify v√† t·∫°o b√°o c√°o import"""
    
    print("=" * 70)
    print("üìä VERIFY MANUAL DOCUMENTS IMPORT")
    print("=" * 70)
    
    try:
        # L·∫•y t·∫•t c·∫£ documents t·ª´ manual import
        result = supabase.table('documents').select('*').like('ghi_chu', '%Import t·ª´ file%').execute()
        
        docs = result.data
        total_docs = len(docs)
        
        print(f"\n‚úÖ Found {total_docs} imported documents")
        
        if total_docs == 0:
            print("‚ùå No documents found!")
            return
        
        # Th·ªëng k√™ theo lo·∫°i vƒÉn b·∫£n
        print("\n" + "=" * 70)
        print("üìã STATISTICS BY DOCUMENT TYPE")
        print("=" * 70)
        
        loai_count = Counter([doc.get('loai', 'N/A') for doc in docs])
        for loai, count in loai_count.most_common():
            print(f"  {loai:30s}: {count:3d} documents")
        
        # Th·ªëng k√™ theo c∆° quan
        print("\n" + "=" * 70)
        print("üè¢ STATISTICS BY ORGANIZATION")
        print("=" * 70)
        
        co_quan_count = Counter([
            doc.get('co_quan_ban_hanh', 'N/A')[:50] if doc.get('co_quan_ban_hanh') else 'N/A' 
            for doc in docs
        ])
        for co_quan, count in co_quan_count.most_common(10):
            print(f"  {co_quan:50s}: {count:3d}")
        
        # Th·ªëng k√™ theo nƒÉm
        print("\n" + "=" * 70)
        print("üìÖ STATISTICS BY YEAR")
        print("=" * 70)
        
        years = []
        for doc in docs:
            date_str = doc.get('ngay_ban_hanh')
            if date_str:
                try:
                    year = date_str[:4]
                    years.append(year)
                except:
                    pass
        
        if years:
            year_count = Counter(years)
            for year, count in sorted(year_count.items(), reverse=True):
                print(f"  {year}: {count:3d} documents")
        else:
            print("  No date information available")
        
        # Documents m·ªõi nh·∫•t
        print("\n" + "=" * 70)
        print("üìÑ RECENT DOCUMENTS (Last 10)")
        print("=" * 70)
        
        recent_docs = sorted(docs, key=lambda x: x.get('id', 0), reverse=True)[:10]
        for i, doc in enumerate(recent_docs, 1):
            print(f"\n  [{i}] ID: {doc.get('id')}")
            print(f"      Ti√™u ƒë·ªÅ: {doc.get('ten', 'N/A')[:60]}")
            print(f"      Lo·∫°i: {doc.get('loai', 'N/A')}")
            print(f"      S·ªë hi·ªáu: {doc.get('so_hieu', 'N/A')}")
            print(f"      Ng√†y: {doc.get('ngay_ban_hanh', 'N/A')}")
        
        # Quality metrics
        print("\n" + "=" * 70)
        print("üìà QUALITY METRICS")
        print("=" * 70)
        
        docs_with_so_hieu = sum(1 for doc in docs if doc.get('so_hieu'))
        docs_with_date = sum(1 for doc in docs if doc.get('ngay_ban_hanh'))
        docs_with_co_quan = sum(1 for doc in docs if doc.get('co_quan_ban_hanh'))
        docs_with_nguoi_ky = sum(1 for doc in docs if doc.get('nguoi_ky'))
        
        print(f"  Documents with S·ªë hi·ªáu:      {docs_with_so_hieu:3d}/{total_docs} ({docs_with_so_hieu/total_docs*100:.1f}%)")
        print(f"  Documents with Ng√†y BH:      {docs_with_date:3d}/{total_docs} ({docs_with_date/total_docs*100:.1f}%)")
        print(f"  Documents with C∆° quan:      {docs_with_co_quan:3d}/{total_docs} ({docs_with_co_quan/total_docs*100:.1f}%)")
        print(f"  Documents with Ng∆∞·ªùi k√Ω:     {docs_with_nguoi_ky:3d}/{total_docs} ({docs_with_nguoi_ky/total_docs*100:.1f}%)")
        
        # Summary
        print("\n" + "=" * 70)
        print("‚úÖ SUMMARY")
        print("=" * 70)
        print(f"  Total documents imported:    {total_docs}")
        print(f"  Document types:              {len(loai_count)}")
        print(f"  Organizations:               {len(co_quan_count)}")
        print(f"  Year range:                  {min(years) if years else 'N/A'} - {max(years) if years else 'N/A'}")
        print(f"  Average metadata quality:    {(docs_with_so_hieu + docs_with_date + docs_with_co_quan + docs_with_nguoi_ky) / (total_docs * 4) * 100:.1f}%")
        
        print("\n‚ú® Verification completed!")
        
    except Exception as e:
        print(f"‚ùå Error: {e}")


def test_search():
    """Test t√¨m ki·∫øm"""
    print("\n" + "=" * 70)
    print("üîç TEST SEARCH FUNCTIONALITY")
    print("=" * 70)
    
    test_keywords = ["ƒêo√†n", "kh·ªüi nghi·ªáp", "thanh ni√™n", "2023"]
    
    for keyword in test_keywords:
        try:
            result = supabase.table('documents').select('id,ten,loai').ilike('ten', f'%{keyword}%').limit(5).execute()
            
            print(f"\n  Keyword: '{keyword}' - Found {len(result.data)} results")
            for doc in result.data[:3]:
                print(f"    - [{doc['id']}] {doc['ten'][:50]}... ({doc['loai']})")
        except Exception as e:
            print(f"  ‚ùå Error searching '{keyword}': {e}")


if __name__ == "__main__":
    verify_import()
    test_search()
